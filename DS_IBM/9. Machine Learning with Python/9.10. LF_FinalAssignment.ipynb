{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3e25b2a1-1c75-4740-aebe-f8f141a1ef94",
      "metadata": {},
      "source": [
        "<p style=\"text-align:center\">\n",
        "    <a href=\"https://skills.network/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML0101ENSkillsNetwork20718538-2022-01-01\" target=\"_blank\">\n",
        "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\">\n",
        "    </a>\n",
        "</p>\n",
        "\n",
        "<h1 align=\"center\"><font size=\"5\">Final Project: Classification with Python</font></h1>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "888f661f-d6dd-4625-a950-b7af2ab4a4a7",
      "metadata": {},
      "source": [
        "# About The Dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ee7647a-c68f-4f68-adb4-f16f1957a694",
      "metadata": {},
      "source": [
        "The original source of the data is Australian Government's Bureau of Meteorology and the latest data can be gathered from [http://www.bom.gov.au/climate/dwo/](http://www.bom.gov.au/climate/dwo/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML0101ENSkillsNetwork20718538-2022-01-01).\n",
        "\n",
        "The dataset to be used has extra columns like 'RainToday' and our target is 'RainTomorrow', which was gathered from the Rattle at [https://bitbucket.org/kayontoga/rattle/src/master/data/weatherAUS.RData](https://bitbucket.org/kayontoga/rattle/src/master/data/weatherAUS.RData?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML0101ENSkillsNetwork20718538-2022-01-01)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54fc9230-6c94-49f8-9ed8-fdac52014f72",
      "metadata": {},
      "source": [
        "This dataset contains observations of weather metrics for each day from 2008 to 2017. The **weatherAUS.csv** dataset includes the following fields:\n",
        "\n",
        "| Field         | Description                                           | Unit            | Type   |\n",
        "| ------------- | ----------------------------------------------------- | --------------- | ------ |\n",
        "| Date          | Date of the Observation in YYYY-MM-DD                 | Date            | object |\n",
        "| Location      | Location of the Observation                           | Location        | object |\n",
        "| MinTemp       | Minimum temperature                                   | Celsius         | float  |\n",
        "| MaxTemp       | Maximum temperature                                   | Celsius         | float  |\n",
        "| Rainfall      | Amount of rainfall                                    | Millimeters     | float  |\n",
        "| Evaporation   | Amount of evaporation                                 | Millimeters     | float  |\n",
        "| Sunshine      | Amount of bright sunshine                             | hours           | float  |\n",
        "| WindGustDir   | Direction of the strongest gust                       | Compass Points  | object |\n",
        "| WindGustSpeed | Speed of the strongest gust                           | Kilometers/Hour | object |\n",
        "| WindDir9am    | Wind direction averaged of 10 minutes prior to 9am    | Compass Points  | object |\n",
        "| WindDir3pm    | Wind direction averaged of 10 minutes prior to 3pm    | Compass Points  | object |\n",
        "| WindSpeed9am  | Wind speed averaged of 10 minutes prior to 9am        | Kilometers/Hour | float  |\n",
        "| WindSpeed3pm  | Wind speed averaged of 10 minutes prior to 3pm        | Kilometers/Hour | float  |\n",
        "| Humidity9am   | Humidity at 9am                                       | Percent         | float  |\n",
        "| Humidity3pm   | Humidity at 3pm                                       | Percent         | float  |\n",
        "| Pressure9am   | Atmospheric pressure reduced to mean sea level at 9am | Hectopascal     | float  |\n",
        "| Pressure3pm   | Atmospheric pressure reduced to mean sea level at 3pm | Hectopascal     | float  |\n",
        "| Cloud9am      | Fraction of the sky obscured by cloud at 9am          | Eights          | float  |\n",
        "| Cloud3pm      | Fraction of the sky obscured by cloud at 3pm          | Eights          | float  |\n",
        "| Temp9am       | Temperature at 9am                                    | Celsius         | float  |\n",
        "| Temp3pm       | Temperature at 3pm                                    | Celsius         | float  |\n",
        "| RainToday     | If there was rain today                               | Yes/No          | object |\n",
        "| RainTomorrow  | If there is rain tomorrow                             | Yes/No          | float  |\n",
        "\n",
        "Column definitions were gathered from [http://www.bom.gov.au/climate/dwo/IDCJDW0000.shtml](http://www.bom.gov.au/climate/dwo/IDCJDW0000.shtml?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML0101ENSkillsNetwork20718538-2022-01-01)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "edfd3145-ceef-4fd9-a6ea-bd33ecfec7e3",
      "metadata": {},
      "source": [
        "## **Import the required libraries**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "bdc34c17-9fce-479a-b050-6e1ccd2c22b9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Surpress warnings:\n",
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "import warnings\n",
        "warnings.warn = warn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "f9004a35-35ce-4d2a-b925-27686e832041",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn import preprocessing\n",
        "import numpy as np\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import jaccard_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "import sklearn.metrics as metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e3cc65e-7e37-4806-844d-d9125bc1c357",
      "metadata": {},
      "source": [
        "### Importing the Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "def download(url, filename):\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "        with open(filename, \"wb\") as f:\n",
        "            f.write(response.content)\n",
        "    else:\n",
        "        raise ValueError(\"Error al descargar el archivo\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "fe327516-e310-4aa2-a520-5c15c3073a75",
      "metadata": {},
      "outputs": [],
      "source": [
        "path='https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-ML0101EN-SkillUp/labs/ML-FinalAssignment/Weather_Data.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "06891094-bcbe-4855-b55c-61e7ec51c92d",
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"Weather_Data.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "512949c4-db76-4be7-9479-111c06fec261",
      "metadata": {},
      "source": [
        "> Note: This version of the lab is designed for JupyterLite, which necessitates downloading the dataset to the interface. However, when working with the downloaded version of this notebook on your local machines (Jupyter Anaconda), you can simply **skip the steps above of \"Importing the Dataset\"** and use the URL directly in the `pandas.read_csv()` function. You can uncomment and run the statements in the cell below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "40479331-9d4a-4f4a-9633-9fd539aa33d1",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>MinTemp</th>\n",
              "      <th>MaxTemp</th>\n",
              "      <th>Rainfall</th>\n",
              "      <th>Evaporation</th>\n",
              "      <th>Sunshine</th>\n",
              "      <th>WindGustDir</th>\n",
              "      <th>WindGustSpeed</th>\n",
              "      <th>WindDir9am</th>\n",
              "      <th>WindDir3pm</th>\n",
              "      <th>...</th>\n",
              "      <th>Humidity9am</th>\n",
              "      <th>Humidity3pm</th>\n",
              "      <th>Pressure9am</th>\n",
              "      <th>Pressure3pm</th>\n",
              "      <th>Cloud9am</th>\n",
              "      <th>Cloud3pm</th>\n",
              "      <th>Temp9am</th>\n",
              "      <th>Temp3pm</th>\n",
              "      <th>RainToday</th>\n",
              "      <th>RainTomorrow</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2/1/2008</td>\n",
              "      <td>19.5</td>\n",
              "      <td>22.4</td>\n",
              "      <td>15.6</td>\n",
              "      <td>6.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>W</td>\n",
              "      <td>41</td>\n",
              "      <td>S</td>\n",
              "      <td>SSW</td>\n",
              "      <td>...</td>\n",
              "      <td>92</td>\n",
              "      <td>84</td>\n",
              "      <td>1017.6</td>\n",
              "      <td>1017.4</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>20.7</td>\n",
              "      <td>20.9</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2/2/2008</td>\n",
              "      <td>19.5</td>\n",
              "      <td>25.6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>3.4</td>\n",
              "      <td>2.7</td>\n",
              "      <td>W</td>\n",
              "      <td>41</td>\n",
              "      <td>W</td>\n",
              "      <td>E</td>\n",
              "      <td>...</td>\n",
              "      <td>83</td>\n",
              "      <td>73</td>\n",
              "      <td>1017.9</td>\n",
              "      <td>1016.4</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>22.4</td>\n",
              "      <td>24.8</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2/3/2008</td>\n",
              "      <td>21.6</td>\n",
              "      <td>24.5</td>\n",
              "      <td>6.6</td>\n",
              "      <td>2.4</td>\n",
              "      <td>0.1</td>\n",
              "      <td>W</td>\n",
              "      <td>41</td>\n",
              "      <td>ESE</td>\n",
              "      <td>ESE</td>\n",
              "      <td>...</td>\n",
              "      <td>88</td>\n",
              "      <td>86</td>\n",
              "      <td>1016.7</td>\n",
              "      <td>1015.6</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>23.5</td>\n",
              "      <td>23.0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2/4/2008</td>\n",
              "      <td>20.2</td>\n",
              "      <td>22.8</td>\n",
              "      <td>18.8</td>\n",
              "      <td>2.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>W</td>\n",
              "      <td>41</td>\n",
              "      <td>NNE</td>\n",
              "      <td>E</td>\n",
              "      <td>...</td>\n",
              "      <td>83</td>\n",
              "      <td>90</td>\n",
              "      <td>1014.2</td>\n",
              "      <td>1011.8</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>21.4</td>\n",
              "      <td>20.9</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2/5/2008</td>\n",
              "      <td>19.7</td>\n",
              "      <td>25.7</td>\n",
              "      <td>77.4</td>\n",
              "      <td>4.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>W</td>\n",
              "      <td>41</td>\n",
              "      <td>NNE</td>\n",
              "      <td>W</td>\n",
              "      <td>...</td>\n",
              "      <td>88</td>\n",
              "      <td>74</td>\n",
              "      <td>1008.3</td>\n",
              "      <td>1004.8</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>22.5</td>\n",
              "      <td>25.5</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 22 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Date  MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine WindGustDir  \\\n",
              "0  2/1/2008     19.5     22.4      15.6          6.2       0.0           W   \n",
              "1  2/2/2008     19.5     25.6       6.0          3.4       2.7           W   \n",
              "2  2/3/2008     21.6     24.5       6.6          2.4       0.1           W   \n",
              "3  2/4/2008     20.2     22.8      18.8          2.2       0.0           W   \n",
              "4  2/5/2008     19.7     25.7      77.4          4.8       0.0           W   \n",
              "\n",
              "   WindGustSpeed WindDir9am WindDir3pm  ...  Humidity9am  Humidity3pm  \\\n",
              "0             41          S        SSW  ...           92           84   \n",
              "1             41          W          E  ...           83           73   \n",
              "2             41        ESE        ESE  ...           88           86   \n",
              "3             41        NNE          E  ...           83           90   \n",
              "4             41        NNE          W  ...           88           74   \n",
              "\n",
              "   Pressure9am  Pressure3pm  Cloud9am  Cloud3pm  Temp9am  Temp3pm  RainToday  \\\n",
              "0       1017.6       1017.4         8         8     20.7     20.9        Yes   \n",
              "1       1017.9       1016.4         7         7     22.4     24.8        Yes   \n",
              "2       1016.7       1015.6         7         8     23.5     23.0        Yes   \n",
              "3       1014.2       1011.8         8         8     21.4     20.9        Yes   \n",
              "4       1008.3       1004.8         8         8     22.5     25.5        Yes   \n",
              "\n",
              "   RainTomorrow  \n",
              "0           Yes  \n",
              "1           Yes  \n",
              "2           Yes  \n",
              "3           Yes  \n",
              "4           Yes  \n",
              "\n",
              "[5 rows x 22 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c2e6b6c-681c-4dab-b8c2-e4b4a3b9865a",
      "metadata": {},
      "source": [
        "### Data Preprocessing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8e184cf-7d18-487e-99b2-d20a5464ebf5",
      "metadata": {},
      "source": [
        "#### One Hot Encoding\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "feaea6fc-58ed-40de-a928-0a0ef688207a",
      "metadata": {},
      "source": [
        "First, we need to perform one hot encoding to convert categorical variables to binary variables.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "66a52820-9b4a-4b7a-af4c-d6e01297dc7f",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_sydney_processed = pd.get_dummies(data=df, columns=['RainToday', 'WindGustDir', 'WindDir9am', 'WindDir3pm'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0826f051-c8d7-4ebb-ae92-4df9654dd747",
      "metadata": {},
      "source": [
        "Next, we replace the values of the 'RainTomorrow' column changing them from a categorical column to a binary column. We do not use the `get_dummies` method because we would end up with two columns for 'RainTomorrow' and we do not want, since 'RainTomorrow' is our target.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "44ed63a3-6587-4ec5-885e-515719079a67",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_sydney_processed.replace(['No', 'Yes'], [0,1], inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e3cfa30-2d2d-4652-878f-a99f0fb02d2f",
      "metadata": {},
      "source": [
        "### Training Data and Test Data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a8c7d85-f098-4d88-ad8e-918448f0a408",
      "metadata": {},
      "source": [
        "Now, we set our 'features' or x values and our Y or target variable.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "97c365ab-97b0-4125-af4f-5ffa38b37ca0",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_sydney_processed.drop('Date',axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "3d0cb951-2eb3-4b7d-99ff-4cdb7b3d5e35",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_sydney_processed = df_sydney_processed.astype(float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "cbc8a10c-b1ad-447a-bf99-a2f391aead0b",
      "metadata": {},
      "outputs": [],
      "source": [
        "features = df_sydney_processed.drop(columns='RainTomorrow', axis=1)\n",
        "Y = df_sydney_processed['RainTomorrow']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0cef42ae-5385-4648-abce-f9e6d1257776",
      "metadata": {},
      "source": [
        "### Linear Regression\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5fd00b7-45ce-4bb5-ad3e-005ee94116f4",
      "metadata": {},
      "source": [
        "#### Q1) Use the `train_test_split` function to split the `features` and `Y` dataframes with a `test_size` of `0.2` and the `random_state` set to `10`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "7a191949-6f38-4994-aee6-c6409fb74c45",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x_train shape: (2616, 66)\n",
            "x_test shape: (655, 66)\n",
            "y_train shape: (2616,)\n",
            "y_test shape: (655,)\n"
          ]
        }
      ],
      "source": [
        "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
        "x_train, x_test, y_train, y_test = train_test_split(features, Y, test_size=0.2, random_state=10)\n",
        "\n",
        "# Mostrar las dimensiones de los conjuntos de datos resultantes\n",
        "print(f\"x_train shape: {x_train.shape}\")\n",
        "print(f\"x_test shape: {x_test.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"y_test shape: {y_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1aa46059-a201-47c9-beeb-b5b67dd03665",
      "metadata": {},
      "source": [
        "#### Q2) Create and train a Linear Regression model called LinearReg using the training data (`x_train`, `y_train`).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "871a7bd7-52bc-4847-b790-331210887ba4",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Coeficientes del modelo: [-2.36917590e-02  1.30054373e-02  7.29815718e-04  6.49074935e-03\n",
            " -3.51643560e-02  4.23764863e-03  1.82923556e-03  7.89868558e-04\n",
            "  9.56084036e-04  8.56062272e-03  7.69810332e-03 -9.24433319e-03\n",
            " -8.87439523e-03  1.00475778e-02  1.44655485e-02 -3.48059951e-03\n",
            "  3.53652210e+08  3.53652210e+08 -1.48636792e+08 -1.48636792e+08\n",
            " -1.48636792e+08 -1.48636792e+08 -1.48636792e+08 -1.48636792e+08\n",
            " -1.48636792e+08 -1.48636792e+08 -1.48636792e+08 -1.48636792e+08\n",
            " -1.48636792e+08 -1.48636792e+08 -1.48636792e+08 -1.48636792e+08\n",
            " -1.48636792e+08 -1.48636792e+08  2.45978566e+08  2.45978566e+08\n",
            "  2.45978566e+08  2.45978566e+08  2.45978566e+08  2.45978566e+08\n",
            "  2.45978566e+08  2.45978566e+08  2.45978566e+08  2.45978566e+08\n",
            "  2.45978566e+08  2.45978566e+08  2.45978566e+08  2.45978566e+08\n",
            "  2.45978566e+08  2.45978566e+08 -1.68435103e+08 -1.68435103e+08\n",
            " -1.68435103e+08 -1.68435103e+08 -1.68435103e+08 -1.68435103e+08\n",
            " -1.68435103e+08 -1.68435103e+08 -1.68435103e+08 -1.68435103e+08\n",
            " -1.68435103e+08 -1.68435103e+08 -1.68435103e+08 -1.68435103e+08\n",
            " -1.68435103e+08 -1.68435103e+08]\n",
            "Intersección del modelo: -282558880.30376893\n"
          ]
        }
      ],
      "source": [
        "# Crear el modelo de Regresión Lineal\n",
        "LinearReg = LinearRegression()\n",
        "\n",
        "# Entrenar el modelo con los datos de entrenamiento\n",
        "LinearReg.fit(x_train, y_train)\n",
        "\n",
        "# Mostrar los coeficientes del modelo\n",
        "print(\"Coeficientes del modelo:\", LinearReg.coef_)\n",
        "print(\"Intersección del modelo:\", LinearReg.intercept_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7caa9b37-022c-483d-bfe4-c0ed7d1877a1",
      "metadata": {},
      "source": [
        "#### Q3) Now use the `predict` method on the testing data (`x_test`) and save it to the array `predictions`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "495fe568-bc5c-46a7-abf7-b8ebfa06e599",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.13183767 0.27618498 0.97818881 0.28745705 0.13241398 0.46046478\n",
            " 0.35678536 0.85640901 0.67501169 0.03824693]\n"
          ]
        }
      ],
      "source": [
        "# Usar el método predict en los datos de prueba\n",
        "predictions = LinearReg.predict(x_test)\n",
        "\n",
        "# Mostrar las primeras 10 predicciones\n",
        "print(predictions[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03e5aca1-3bf5-4527-9298-35b140218d78",
      "metadata": {},
      "source": [
        "#### Q4) Using the `predictions` and the `y_test` dataframe calculate the value for each metric using the appropriate function.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Absolute Error (MAE): 0.25631750276070514\n",
            "Mean Squared Error (MSE): 0.11572058030841967\n",
            "R-squared (R²): 0.42713211983268984\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Calcular el Mean Absolute Error (MAE)\n",
        "LinearRegression_MAE = mean_absolute_error(y_test, predictions)\n",
        "print(\"Mean Absolute Error (MAE):\", LinearRegression_MAE)\n",
        "\n",
        "# Calcular el Mean Squared Error (MSE)\n",
        "LinearRegression_MSE = mean_squared_error(y_test, predictions)\n",
        "print(\"Mean Squared Error (MSE):\", LinearRegression_MSE)\n",
        "\n",
        "# Calcular el R-squared (R²)\n",
        "LinearRegression_R2 = r2_score(y_test, predictions)\n",
        "print(\"R-squared (R²):\", LinearRegression_R2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd4e4765-58df-42f7-b7b2-cbd333edd2b4",
      "metadata": {},
      "source": [
        "#### Q5) Show the MAE, MSE, and R2 in a tabular format using data frame for the linear model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "3514ec1c-2340-4788-a00e-a44ace58afd4",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                      Metric     Value\n",
            "0  Mean Absolute Error (MAE)  0.256318\n",
            "1   Mean Squared Error (MSE)  0.115721\n",
            "2             R-squared (R²)  0.427132\n"
          ]
        }
      ],
      "source": [
        "# Crear un diccionario con las métricas\n",
        "metrics = {\n",
        "    'Metric': ['Mean Absolute Error (MAE)', 'Mean Squared Error (MSE)', 'R-squared (R²)'],\n",
        "    'Value': [LinearRegression_MAE, LinearRegression_MSE, LinearRegression_R2]\n",
        "}\n",
        "\n",
        "# Crear un DataFrame a partir del diccionario\n",
        "report = pd.DataFrame(metrics)\n",
        "\n",
        "# Mostrar el DataFrame\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99695b77-5363-4de0-a26c-baf7ef296d14",
      "metadata": {},
      "source": [
        "### KNN\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e485f53-f6f1-4924-8417-f67271b3a9c8",
      "metadata": {},
      "source": [
        "#### Q6) Create and train a KNN model called KNN using the training data (`x_train`, `y_train`) with the `n_neighbors` parameter set to `4`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "743a8c94-a0e1-4785-8353-b7a66958cb8b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "KNeighborsClassifier(n_neighbors=4)\n"
          ]
        }
      ],
      "source": [
        "# Crear el modelo KNN con n_neighbors=4\n",
        "KNN = KNeighborsClassifier(n_neighbors=4)\n",
        "\n",
        "# Entrenar el modelo con los datos de entrenamiento\n",
        "KNN.fit(x_train, y_train)\n",
        "\n",
        "# Mostrar el modelo entrenado\n",
        "print(KNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3f04498-d929-4f38-be04-5e8113396beb",
      "metadata": {},
      "source": [
        "#### Q7) Now use the `predict` method on the testing data (`x_test`) and save it to the array `predictions`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "140ca0a5-2dc9-44a7-93c2-f78127a354a8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0. 0. 1. 0. 0. 0. 0. 1. 1. 0.]\n"
          ]
        }
      ],
      "source": [
        "# Usar el método predict en los datos de prueba\n",
        "predictions = KNN.predict(x_test)\n",
        "\n",
        "# Mostrar las primeras 10 predicciones\n",
        "print(predictions[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "003b1288-9942-406c-9811-eee84f2df091",
      "metadata": {},
      "source": [
        "#### Q8) Using the `predictions` and the `y_test` dataframe calculate the value for each metric using the appropriate function.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy Score: 0.8183206106870229\n",
            "Jaccard Index: 0.4251207729468599\n",
            "F1 Score: 0.5966101694915255\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, jaccard_score, f1_score\n",
        "\n",
        "# Calcular el Accuracy Score\n",
        "KNN_Accuracy_Score = accuracy_score(y_test, predictions)\n",
        "print(\"Accuracy Score:\", KNN_Accuracy_Score)\n",
        "\n",
        "# Calcular el Jaccard Index\n",
        "KNN_JaccardIndex = jaccard_score(y_test, predictions)\n",
        "print(\"Jaccard Index:\", KNN_JaccardIndex)\n",
        "\n",
        "# Calcular el F1 Score\n",
        "KNN_F1_Score = f1_score(y_test, predictions)\n",
        "print(\"F1 Score:\", KNN_F1_Score)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9c0101b-83e4-43a0-b4a9-864758dfbd12",
      "metadata": {},
      "source": [
        "### Decision Tree\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a47408a-8e4e-4e2d-8380-4ae1c57e481c",
      "metadata": {},
      "source": [
        "#### Q9) Create and train a Decision Tree model called Tree using the training data (`x_train`, `y_train`).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "e909447d-f37e-41de-9b3c-1e7d84c58027",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DecisionTreeClassifier()\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Crear el modelo de Árbol de Decisión\n",
        "Tree = DecisionTreeClassifier()\n",
        "\n",
        "# Entrenar el modelo con los datos de entrenamiento\n",
        "Tree.fit(x_train, y_train)\n",
        "\n",
        "# Mostrar el modelo entrenado\n",
        "print(Tree)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3dbb3bad-45af-44c2-81fa-0b1a101c636e",
      "metadata": {},
      "source": [
        "#### Q10) Now use the `predict` method on the testing data (`x_test`) and save it to the array `predictions`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "c92e47de-aeea-4efa-8f06-2b2f3546494a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0. 0. 1. 0. 0. 1. 1. 1. 1. 1.]\n"
          ]
        }
      ],
      "source": [
        "# Usar el método predict en los datos de prueba\n",
        "predictions = Tree.predict(x_test)\n",
        "\n",
        "# Mostrar las primeras 10 predicciones\n",
        "print(predictions[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f62e69e-6778-43b0-aa82-4d04107acd63",
      "metadata": {},
      "source": [
        "#### Q11) Using the `predictions` and the `y_test` dataframe calculate the value for each metric using the appropriate function.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "ac39549e-e175-497a-87b7-635362b43460",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy Score: 0.7526717557251908\n",
            "Jaccard Index: 0.39552238805970147\n",
            "F1 Score: 0.5668449197860963\n"
          ]
        }
      ],
      "source": [
        "# Calcular el Accuracy Score\n",
        "Tree_Accuracy_Score = accuracy_score(y_test, predictions)\n",
        "print(\"Accuracy Score:\", Tree_Accuracy_Score)\n",
        "\n",
        "# Calcular el Jaccard Index\n",
        "Tree_JaccardIndex = jaccard_score(y_test, predictions)\n",
        "print(\"Jaccard Index:\", Tree_JaccardIndex)\n",
        "\n",
        "# Calcular el F1 Score\n",
        "Tree_F1_Score = f1_score(y_test, predictions)\n",
        "print(\"F1 Score:\", Tree_F1_Score)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e9e7a03-a6b2-4c19-8ca6-2bc049cebc9c",
      "metadata": {},
      "source": [
        "### Logistic Regression\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0482cc1-21a7-401e-94e7-9aa2e50f1404",
      "metadata": {},
      "source": [
        "#### Q12) Use the `train_test_split` function to split the `features` and `Y` dataframes with a `test_size` of `0.2` and the `random_state` set to `1`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "c6ffd905-3443-47d4-b4c0-18a117755e77",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x_train shape: (2616, 66)\n",
            "x_test shape: (655, 66)\n",
            "y_train shape: (2616,)\n",
            "y_test shape: (655,)\n"
          ]
        }
      ],
      "source": [
        "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
        "x_train, x_test, y_train, y_test = train_test_split(features, Y, test_size=0.2, random_state=1)\n",
        "\n",
        "# Mostrar las dimensiones de los conjuntos de datos resultantes\n",
        "print(f\"x_train shape: {x_train.shape}\")\n",
        "print(f\"x_test shape: {x_test.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"y_test shape: {y_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c484345e-e801-432c-8615-a92f72ba9d71",
      "metadata": {},
      "source": [
        "#### Q13) Create and train a LogisticRegression model called LR using the training data (`x_train`, `y_train`) with the `solver` parameter set to `liblinear`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "b4e10d23-92f8-40be-b712-bf04c1240dd8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LogisticRegression(solver='liblinear')\n"
          ]
        }
      ],
      "source": [
        "# Crear el modelo de Regresión Logística con solver='liblinear'\n",
        "LR = LogisticRegression(solver='liblinear')\n",
        "\n",
        "# Entrenar el modelo con los datos de entrenamiento\n",
        "LR.fit(x_train, y_train)\n",
        "\n",
        "# Mostrar el modelo entrenado\n",
        "print(LR)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e507e6a-d838-41c7-b02e-fc6059966b1d",
      "metadata": {},
      "source": [
        "#### Q14) Now, use the `predict` and `predict_proba` methods on the testing data (`x_test`) and save it as 2 arrays `predictions` and `predict_proba`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "6ebb6845-f367-4884-a59c-a94fff42d1be",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predictions: [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            "Predict probabilities: [[0.73904428 0.26095572]\n",
            " [0.9751503  0.0248497 ]\n",
            " [0.51804839 0.48195161]\n",
            " [0.84542632 0.15457368]\n",
            " [0.96869692 0.03130308]\n",
            " [0.06509102 0.93490898]\n",
            " [0.71062837 0.28937163]\n",
            " [0.96214162 0.03785838]\n",
            " [0.92206113 0.07793887]\n",
            " [0.9346626  0.0653374 ]]\n"
          ]
        }
      ],
      "source": [
        "# Usar el método predict en los datos de prueba\n",
        "predictions = LR.predict(x_test)\n",
        "\n",
        "# Usar el método predict_proba en los datos de prueba\n",
        "predict_proba = LR.predict_proba(x_test)\n",
        "\n",
        "# Mostrar las primeras 10 predicciones y probabilidades\n",
        "print(\"Predictions:\", predictions[:10])\n",
        "print(\"Predict probabilities:\", predict_proba[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8512dbb-b19b-4d3b-a1f4-ab9695c378d4",
      "metadata": {},
      "source": [
        "#### Q15) Using the `predictions`, `predict_proba` and the `y_test` dataframe calculate the value for each metric using the appropriate function.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "bd7367b5-cd89-4db8-aaab-913676b3dfad",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy Score: 0.8366412213740458\n",
            "Jaccard Index: 0.5091743119266054\n",
            "F1 Score: 0.6747720364741642\n",
            "Log Loss: 0.38045106723472155\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, jaccard_score, f1_score, log_loss\n",
        "\n",
        "# Calcular el Accuracy Score\n",
        "LR_Accuracy_Score = accuracy_score(y_test, predictions)\n",
        "print(\"Accuracy Score:\", LR_Accuracy_Score)\n",
        "\n",
        "# Calcular el Jaccard Index\n",
        "LR_JaccardIndex = jaccard_score(y_test, predictions)\n",
        "print(\"Jaccard Index:\", LR_JaccardIndex)\n",
        "\n",
        "# Calcular el F1 Score\n",
        "LR_F1_Score = f1_score(y_test, predictions)\n",
        "print(\"F1 Score:\", LR_F1_Score)\n",
        "\n",
        "# Calcular el Log Loss\n",
        "LR_Log_Loss = log_loss(y_test, predict_proba)\n",
        "print(\"Log Loss:\", LR_Log_Loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94298343-aca9-4311-a267-a8ac024b1033",
      "metadata": {},
      "source": [
        "### SVM\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e7f9a35-fb3f-487c-9d96-47bd17df393d",
      "metadata": {},
      "source": [
        "#### Q16) Create and train a SVM model called SVM using the training data (`x_train`, `y_train`).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "37b64a59-7e29-4e4f-a689-065c1819fc96",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SVC()\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "# Crear el modelo SVM\n",
        "SVM = SVC()\n",
        "\n",
        "# Entrenar el modelo con los datos de entrenamiento\n",
        "SVM.fit(x_train, y_train)\n",
        "\n",
        "# Mostrar el modelo entrenado\n",
        "print(SVM)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e50e7032-0b80-414c-93ea-e35ff941e49b",
      "metadata": {},
      "source": [
        "#### Q17) Now use the `predict` method on the testing data (`x_test`) and save it to the array `predictions`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "aeeca7de-09d5-45ad-aacc-f0457ca6ee37",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ],
      "source": [
        "# Usar el método predict en los datos de prueba\n",
        "predictions = SVM.predict(x_test)\n",
        "\n",
        "# Mostrar las primeras 10 predicciones\n",
        "print(predictions[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87096852-98e6-4115-bdb2-a8603cee605a",
      "metadata": {},
      "source": [
        "#### Q18) Using the `predictions` and the `y_test` dataframe calculate the value for each metric using the appropriate function.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "da8140a8-563e-4b01-be32-869b8120c85e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy Score: 0.7221374045801526\n",
            "Jaccard Index: 0.0\n",
            "F1 Score: 0.0\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, jaccard_score, f1_score\n",
        "\n",
        "# Calcular el Accuracy Score\n",
        "SVM_Accuracy_Score = accuracy_score(y_test, predictions)\n",
        "print(\"Accuracy Score:\", SVM_Accuracy_Score)\n",
        "\n",
        "# Calcular el Jaccard Index\n",
        "SVM_JaccardIndex = jaccard_score(y_test, predictions)\n",
        "print(\"Jaccard Index:\", SVM_JaccardIndex)\n",
        "\n",
        "# Calcular el F1 Score\n",
        "SVM_F1_Score = f1_score(y_test, predictions)\n",
        "print(\"F1 Score:\", SVM_F1_Score)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c359d67e-2279-48f7-8f4e-5cfbce38787f",
      "metadata": {},
      "source": [
        "### Report\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b34aeff-18d6-4f17-99ee-bb66f6cdb5ec",
      "metadata": {},
      "source": [
        "#### Q19) Show the Accuracy,Jaccard Index,F1-Score and LogLoss in a tabular format using data frame for all of the above models.\n",
        "\n",
        "\\*LogLoss is only for Logistic Regression Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "b641ad9b-6453-4d42-b0c2-ae4847728180",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                 Model  Accuracy Score  Jaccard Index  F1 Score  Log Loss\n",
            "0    Linear Regression        0.256318            NaN       NaN       NaN\n",
            "1                  KNN        0.818321       0.425121  0.596610       NaN\n",
            "2        Decision Tree        0.752672       0.395522  0.566845       NaN\n",
            "3  Logistic Regression        0.836641       0.509174  0.674772  0.380451\n",
            "4                  SVM        0.722137       0.000000  0.000000       NaN\n"
          ]
        }
      ],
      "source": [
        "# Crear un diccionario con las métricas\n",
        "metrics = {\n",
        "    'Model': ['Linear Regression', 'KNN', 'Decision Tree', 'Logistic Regression', 'SVM'],\n",
        "    'Accuracy Score': [LinearRegression_MAE, KNN_Accuracy_Score, Tree_Accuracy_Score, LR_Accuracy_Score, SVM_Accuracy_Score],\n",
        "    'Jaccard Index': [None, KNN_JaccardIndex, Tree_JaccardIndex, LR_JaccardIndex, SVM_JaccardIndex],\n",
        "    'F1 Score': [None, KNN_F1_Score, Tree_F1_Score, LR_F1_Score, SVM_F1_Score],\n",
        "    'Log Loss': [None, None, None, LR_Log_Loss, None]\n",
        "}\n",
        "\n",
        "# Crear un DataFrame a partir del diccionario\n",
        "report = pd.DataFrame(metrics)\n",
        "\n",
        "# Mostrar el DataFrame\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e26f707c-9e55-46f8-a96e-d683ead0d845",
      "metadata": {},
      "source": [
        "<h2 id=\"Section_5\">  How to submit </h2>\n",
        "\n",
        "<p>Once you complete your notebook you will have to share it. You can download the notebook by navigating to \"File\" and clicking on \"Download\" button.\n",
        "\n",
        "<p>This will save the (.ipynb) file on your computer. Once saved, you can upload this file in the \"My Submission\" tab, of the \"Peer-graded Assignment\" section.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7998511d-7e88-4f2f-95f5-6d27bcb167f1",
      "metadata": {},
      "source": [
        "<h2>About the Authors:</h2> \n",
        "\n",
        "<a href=\"https://www.linkedin.com/in/joseph-s-50398b136/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML0101ENSkillsNetwork20718538-2022-01-01\">Joseph Santarcangelo</a> has a PhD in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his PhD.\n",
        "\n",
        "### Other Contributors\n",
        "\n",
        "[Svitlana Kramar](https://www.linkedin.com/in/svitlana-kramar/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0232ENSkillsNetwork30654641-2022-01-01)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90cd7956-858f-47af-8890-dd86a9387fe6",
      "metadata": {},
      "source": [
        "## <h3 align=\"center\"> © IBM Corporation 2020. All rights reserved. <h3/>\n",
        "\n",
        "<!--\n",
        "## Change Log\n",
        "\n",
        "| Date (YYYY-MM-DD) | Version | Changed By    | Change Description          |\n",
        "| ----------------- | ------- | ------------- | --------------------------- |\n",
        "| 2022-06-22        | 2.0     | Svitlana K.   | Deleted GridSearch and Mock |\n",
        "--!>"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "prev_pub_hash": "b45b938fc7420206c5fa3f040f896f2a578fd1045d763cf82b4c02f8772d2aee"
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
